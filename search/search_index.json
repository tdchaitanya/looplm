{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LoopLM - Loop Language Models in your day-to-day tasks.","text":"<p>\ud83d\udeab\ud83d\udeab\ud83d\udeab This tool is still in active development</p> <p><code>looplm</code> -- Loop LM is a highly customisable command-line interface for interacting with various Language Models. It provides a simple and straighforward way to access state-of-the-art language models directly from your terminal and helps you leverage LLMs in your day-to-day software development workflows</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\ude80 Support for multiple LLM providers: Works with OpenAI, Anthropic, Google Gemini, Azure OpenAI, AWS Bedrock, and other providers through LiteLLM integration. You can easily switch between different providers and models</li> <li>\ud83d\udd12 Secure Configuration: All API keys and credentials are stored securely using encryption</li> <li>\ud83d\udcbb Simple CLI: Intuitive command-line interface for quick access to AI capabilities</li> <li>\ud83d\udd0d Rich Output: Beautiful terminal output with markdown support</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li> <p>Install LoopLM using pipx: <pre><code>pipx install looplm\n</code></pre></p> </li> <li> <p>Configure your first provider: <pre><code>looplm --configure\n</code></pre></p> </li> <li> <p>Start using the CLI: <pre><code>looplm \"Write a function to calculate fibonacci numbers in Python\"\n</code></pre></p> </li> </ol>"},{"location":"#why-looplm","title":"Why LoopLM?","text":"<p>LoopLM is designed for developers who: - Want quick access to LLMs without leaving the terminal - Work with multiple LLM providers and need a unified interface - Want to integrate LLM assistance into their development workflow</p>"},{"location":"#requirementss","title":"Requirementss","text":"<ul> <li>Python 3.10 or higher</li> <li>API keys for the providers you want to use</li> </ul>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>LoopLM provides a straightforward way to configure different LLM providers. All configuration is handled through the CLI, with credentials stored securely using encryption.</p>"},{"location":"configuration/#initial-setup","title":"Initial Setup","text":"<p>To start configuring LoopLM, run:</p> <pre><code>looplm --configure\n</code></pre> <p>This will launch an interactive setup process where you can configure one or more providers.</p>"},{"location":"configuration/#supported-providers","title":"Supported Providers","text":"<p>LoopLM supports the following providers:</p>"},{"location":"configuration/#anthropic","title":"Anthropic","text":"<p>Required environment variables: - <code>ANTHROPIC_API_KEY</code></p> <p>Example model: <code>claude-3-5-sonnet-20240620</code></p>"},{"location":"configuration/#openai","title":"OpenAI","text":"<p>Required environment variables: - <code>OPENAI_API_KEY</code></p> <p>Example model: <code>gpt-4o</code></p>"},{"location":"configuration/#google-gemini","title":"Google Gemini","text":"<p>Required environment variables: - <code>GEMINI_API_KEY</code></p> <p>Example model: <code>gemini/gemini-pro</code></p>"},{"location":"configuration/#azure-openai","title":"Azure OpenAI","text":"<p>Required environment variables: - <code>AZURE_API_KEY</code> - <code>AZURE_API_BASE</code> - <code>AZURE_API_VERSION</code></p> <p>Example model: <code>azure/gpt-4o</code></p>"},{"location":"configuration/#aws-bedrock","title":"AWS Bedrock","text":"<p>Required environment variables: - <code>AWS_ACCESS_KEY_ID</code> - <code>AWS_SECRET_ACCESS_KEY</code> - <code>AWS_REGION_NAME</code></p> <p>Example model: <code>anthropic.claude-3-5-sonnet-20240620-v1:0</code></p>"},{"location":"configuration/#other-providers","title":"Other Providers","text":"<p>LoopLM supports any provider that's compatible with LiteLLM. When configuring other providers, you'll need to:</p> <ol> <li>Specify the provider name</li> <li>Enter the required environment variables</li> <li>Specify the model name according to LiteLLM's documentation</li> </ol>"},{"location":"configuration/#configuration-commands","title":"Configuration Commands","text":""},{"location":"configuration/#view-current-configuration","title":"View Current Configuration","text":"<pre><code>looplm --status\n</code></pre> <p>This shows: - Configured providers - Default provider and model - Provider status</p>"},{"location":"configuration/#set-default-provider","title":"Set Default Provider","text":"<pre><code>looplm --set-default &lt;provider&gt;\n</code></pre> <p>Example: <pre><code>looplm --set-default anthropic\n</code></pre></p>"},{"location":"configuration/#reset-configuration","title":"Reset Configuration","text":"<p>Reset all configuration: <pre><code>looplm --reset\n</code></pre></p> <p>Reset specific provider: <pre><code>looplm --reset-provider anthropic\n</code></pre></p>"},{"location":"configuration/#configuration-storage","title":"Configuration Storage","text":"<p>LoopLM stores configuration in two locations in your home directory:</p> <ol> <li><code>.looplm/config.json</code>: General configuration (non-sensitive)</li> <li><code>.looplm/secrets.enc</code>: Encrypted API keys and credentials</li> </ol> <p>The configuration is encrypted using Fernet symmetric encryption, ensuring your API keys remain secure.</p>"},{"location":"configuration/#additional-environment-variables","title":"Additional Environment Variables","text":"<p>When configuring a provider, you can set additional environment variables that might be required for your specific use case. These will be stored securely with your other credentials.</p>"},{"location":"usage/","title":"Usage Guide","text":"<p>LoopLM provides a simple yet powerful command-line interface for interacting with Language Models. Here's how to make the most of it.</p>"},{"location":"usage/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/#simple-prompt","title":"Simple Prompt","text":"<pre><code>looplm \"Write a Python function to sort a dictionary by values\"\n</code></pre> <p>This uses your default provider and model to process the prompt.</p>"},{"location":"usage/#specify-provider","title":"Specify Provider","text":"<pre><code>looplm --provider anthropic \"Explain quantum computing\"\n</code></pre>"},{"location":"usage/#specify-model","title":"Specify Model","text":"<pre><code>looplm --provider openai --model gpt-4o \"Write a regex for email validation\"\n</code></pre>"},{"location":"usage/#command-structure","title":"Command Structure","text":"<p>The basic command structure is:</p> <pre><code>looplm [OPTIONS] PROMPT\n</code></pre>"},{"location":"usage/#available-options","title":"Available Options","text":"<ul> <li><code>--provider</code>: Use a specific provider</li> <li><code>--model</code>: Use a specific model</li> <li><code>--configure</code>: Launch configuration setup</li> <li><code>--status</code>: Show current configuration</li> <li><code>--reset</code>: Reset all configuration</li> <li><code>--reset-provider</code>: Reset specific provider configuration</li> <li><code>--set-default</code>: Set default provider and model</li> </ul>"},{"location":"usage/#example-use-cases","title":"Example Use Cases","text":""},{"location":"usage/#development-assistance","title":"Development Assistance","text":"<ol> <li> <p>Code Explanation <pre><code>looplm \"Explain what this code does: $(cat complex_function.py)\"\n</code></pre></p> </li> <li> <p>Debug Help <pre><code>looplm \"Help me debug this error: $(cat error_log.txt)\"\n</code></pre></p> </li> <li> <p>Code Generation <pre><code>looplm \"Write a Python script to backup files older than 30 days\"\n</code></pre></p> </li> </ol>"},{"location":"usage/#documentation","title":"Documentation","text":"<ol> <li> <p>Generate Docstrings <pre><code>looplm \"Write a detailed docstring for this function: $(cat function.py)\"\n</code></pre></p> </li> <li> <p>README Creation <pre><code>looplm \"Write a README for a Python package that does web scraping\"\n</code></pre></p> </li> </ol>"},{"location":"usage/#learning","title":"Learning","text":"<ol> <li> <p>Concept Explanation <pre><code>looplm \"Explain how async/await works in Python\"\n</code></pre></p> </li> <li> <p>Best Practices <pre><code>looplm \"What are the best practices for Python error handling?\"\n</code></pre></p> </li> </ol>"},{"location":"usage/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"usage/#1-using-with-pipes","title":"1. Using with Pipes","text":"<p>LoopLM works well with Unix pipes:</p> <pre><code>cat error.log | looplm \"Explain this error and suggest solutions\"\n</code></pre>"},{"location":"usage/#2-shell-aliases","title":"2. Shell Aliases","text":"<p>Create useful aliases for common tasks:</p> <pre><code># Add to your .bashrc or .zshrc\nalias explain='looplm \"Explain what this code does: \"'\nalias debug='looplm \"Help debug this error: \"'\nalias docstring='looplm \"Write a docstring for: \"'\n</code></pre>"},{"location":"usage/#3-multiple-lines","title":"3. Multiple Lines","text":"<p>For multiple-line prompts, use quotes:</p> <pre><code>looplm \"Review this code and suggest improvements:\n\ndef process_data(data):\n    result = []\n    for item in data:\n        if item &gt; 0:\n            result.append(item * 2)\n    return result\"\n</code></pre>"},{"location":"usage/#4-script-integration","title":"4. Script Integration","text":"<p>You can integrate LoopLM into your scripts:</p> <pre><code>#!/bin/bash\nerror_output=$(your_command 2&gt;&amp;1)\nif [ $? -ne 0 ]; then\n    looplm \"Help debug this error: $error_output\"\nfi\n</code></pre>"}]}